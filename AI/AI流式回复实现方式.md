# AI流式回复实现方式

1. 基于 Server-Sent Events (SSE) 的流式回复
   1. 特点：
      1. 单向通信：服务器->客户端实时推送文本流
      2. 基于 HTTP:实现简单，浏览器原生支持（通过 EventSource） 
      3. 自动重连、轻量级、省电，适合移动端
      4. 文本流格式清晰，通常按`data:...\n\n`分块推送
   2. 实现方式：
      1. 服务端在生成 AI 回复时，逐块（token-by-token 或 chunk-by-chunk）输出，并通过 HTTP 长连接实时推送
      2. 前端使用 `EventSource` 接收数据，并实时显示
   3. 适用场景：
      1. 纯展示类流式回复，如 AI 聊天、内容生成、代码补全等
      2. 不需要客户端主动干预（如暂停、修改提示词）
2. 基于 WebSocket 的流式回复 - 基于 `TCP 协议`
   1. 特点
      1. 全双工通信：客户端和服务端可双向实时交互
      2. 适合需要客户端控制的场景（如中断生成、重新提示、多轮对话管理）
      3. 传输效率高，适合高频交互
   2. 实现方式：
      1. 服务器与客户端通过 websocket 建立长连接
      2. AI 生成内容时，服务器通过 websocket 实时推送文本片段
      3. 前端接收后动态渲染到页面
   3. 适用场景：
      1. 交互型AI应用，如智能客服、聊天机器人、需要用户实时控制生成流程的场景
3. 基于 HTTP Chunked 流式传输（Streaming over HTTP）
   1. 特点：
      1. 利用 HTTP/1.1 或 HTTP/2 的分块传输编码（Transfer-Encoding: chunked）
      2. 服务端逐步输出内容，前端通过 AJAX(Fetch/XHR)或 Fetch+ReadableStream 实时接收
      3. 常用于 Fetch API 流式读取，如 `response.body.getReader()`
   2. 实现方式：
      1. 服务端以流式方式逐步返回文本（如每生成一个 token 返回一次）
      2. 前端使用 `fetch()`请求，并通过 ReadableStream 逐块消费响应体，实时显示
   3. 适用场景：
      1. 希望不依赖 `SSE` 或`Websocket`,仅用 HTTP 就能实现流式效果的轻量级方案
      2. 适合对连接控制要求更高、需定制交互逻辑的场景


## SSE 的连接数限制

造成SSE 连接数限制的主要原因是

1. 浏览器对单个域名的 HTTP 连接数限制：通常 6-8个，超过后新连接会被阻塞 `有上限`
2. 服务器能支持的 SSE 并发连接数：受服务器资源、配置、负载均衡策略等限制，可能从几百到几万不等 `有上限`
3. 客户端设备限制：移动端、弱网、浏览器标签过多等都会影响连接稳定性`间接有上限`
4. SSE 本身并没有连接数限制 `无明确限制`

## WebSocket 的连接数限制

造成 WebSocket 连接数限制的主要原因是

1. 浏览器对单个域名的 HTTP 连接数限制：通常 6-8个，超过后新连接会被阻塞 `有上限`
2. 服务器能支持的 WebSocket 并发连接数：受服务器资源、配置、负载均衡策略等限制，可能从几百到几万不等 `有上限`
3. 客户端设备限制：移动端、网络环境可能影响连接稳定性`间接有上限`
4. WebSocket 本身并没有连接数限制，但实际收运行环境影响 `无明确限制`
